{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s2537809/DESI/desispec/py/desispec/qproc/qextract.py:19: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def numba_extract(image_flux,image_var,x,hw=3) :\n",
      "/Users/s2537809/DESI/desispec/py/desispec/image_model.py:27: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def numba_proj(image,x,sigma,flux) :\n",
      "/Users/s2537809/DESI/desispec/py/desispec/preproc.py:379: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def numba_mean(image_flux,image_ivar,x,hw=3) :\n"
     ]
    }
   ],
   "source": [
    "from astropy.table import Table, vstack, Column, MaskedColumn, pprint\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.convolution import convolve, Gaussian1DKernel\n",
    "\n",
    "from astropy.io import fits\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "sys.path.append('/Users/s2537809/DESI/desispec/py')\n",
    "sys.path.append('/Users/s2537809/DESI/desimodel/py')\n",
    "sys.path.append('/Users/s2537809/DESI/desitarget/py')\n",
    "sys.path.append('/Users/s2537809/DESI/desiutil/py')\n",
    "\n",
    "#from desispec.io import read_spectra\n",
    "# import DESI related modules - \n",
    "from desimodel.footprint import radec2pix      # For getting healpix values\n",
    "import desispec.io                             # Input/Output functions related to DESI spectra\n",
    "from desispec import coaddition                # Functions related to coadding the spectra\n",
    "\n",
    "\n",
    "from scipy import interpolate\n",
    "import astropy.units as u\n",
    "path='/Users/s2537809/Documents/DESI-STACKING'#specify code directory\n",
    "os.chdir(path)\n",
    "import stack_code as sc\n",
    "import importlib\n",
    "import fnmatch\n",
    "import extinction as ext\n",
    "from scipy.optimize import curve_fit\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.modeling import models\n",
    "from astropy.table import Table\n",
    "from matplotlib import gridspec\n",
    "import spectres\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "import warnings\n",
    "from astropy.modeling import models\n",
    "from astropy import units as u\n",
    "from specutils.spectra import Spectrum1D, SpectralRegion\n",
    "from specutils.fitting import fit_generic_continuum\n",
    "from specutils.analysis import equivalent_width\n",
    "\n",
    "\n",
    "#pip install lmfit, extinction, sfdmap, spectres\n",
    "\n",
    "import pandas as pd\n",
    "crossmatch = Table.read('crossmatch_classifications.fits', format = 'fits' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7533\n",
      "27\n",
      "5547\n",
      "7461\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Remove the objects with failed redshift classifications.\n",
    "First applying their ZWARN flag, then with the photo-z quality flag.\n",
    "\"\"\"\n",
    "\n",
    "# Apply ZWARN Flag cut\n",
    "crossmatch = crossmatch[crossmatch['ZWARN'] == 0]\n",
    "\n",
    "# Create photo-z quality flag\n",
    "crossmatch['Z_CHECK']= (crossmatch['Z']-crossmatch['Z_BEST_1'])/(1+crossmatch['Z'])\n",
    "crossmatch['Z_FAILURE'] = 0  \n",
    "crossmatch['Z_FAILURE'][abs(crossmatch['Z_CHECK']) > 0.1] = 1 \n",
    "\n",
    "# Apply photo-z quality flag\n",
    "crossmatch = crossmatch[crossmatch['Z_FAILURE'] == 0]\n",
    "print(len(crossmatch))\n",
    "print(len(crossmatch[crossmatch['Z'] < 0]))\n",
    "print(len(crossmatch[crossmatch['Overall_class'] == 'SFG']))\n",
    "\n",
    "# Remove objects with no SFR or Mass\n",
    "crossmatch = crossmatch[crossmatch['SFR_cons'] != -99]\n",
    "crossmatch = crossmatch[crossmatch['Mass_cons'] != -99] \n",
    "\n",
    "\n",
    "print(len(crossmatch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell below verifies if Spectra are downloaded and downloads if they aren't\n",
    "\n",
    "Only run if unsure if spectra are downloaded, to save time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Overall_class = 'SFG'\n",
    "my_table = crossmatch[crossmatch['Overall_class'] == f'{Overall_class}'][1000:1200]\n",
    "search_column_name = 'TARGETID'\n",
    "search_values = np.array(my_table[f'{search_column_name}'])\n",
    "\n",
    "\n",
    "\n",
    "def select_data(table, column_name, search_values):\n",
    "    # Get the column data as a numpy array\n",
    "    column_data = table[column_name]\n",
    "\n",
    "    SURVEY = []\n",
    "    PROGRAM = []\n",
    "    HEALPIX = []\n",
    "    n_values = []\n",
    "    Z = []\n",
    "    \n",
    "\n",
    "    for search_value in search_values:\n",
    "        # Find the indices where the condition is met (value == search_value)\n",
    "        indices = np.where(column_data == search_value)[0]\n",
    "\n",
    "\n",
    "        if len(indices) > 0:\n",
    "            # Find the corresponding Survey, program, healpix, and Z values\n",
    "            SURVEY.append(table['SURVEY'][indices[0]])\n",
    "            PROGRAM.append(table['PROGRAM'][indices[0]])\n",
    "            HEALPIX.append(table['HEALPIX'][indices[0]])\n",
    "            Z.append(table['Z'][indices[0]])\n",
    "            HEALPIX_str = str(table['HEALPIX'][indices[0]])\n",
    "            n_str = HEALPIX_str[:3]\n",
    "            n_values.append(int(n_str))\n",
    "        else:\n",
    "            # Handle the case where the search value was not found\n",
    "            SURVEY.append(None)\n",
    "            PROGRAM.append(None)\n",
    "            HEALPIX.append(None)\n",
    "            n_values.append(None)\n",
    "            Z.append(None)\n",
    "    \n",
    "\n",
    "    return np.array(SURVEY), np.array(PROGRAM), np.array(HEALPIX), np.array(n_values), np.array(Z), \n",
    "\n",
    "\n",
    "SURVEY = select_data(my_table, search_column_name, search_values)[0]\n",
    "PROGRAM = select_data(my_table, search_column_name, search_values)[1]\n",
    "HEALPIX = select_data(my_table, search_column_name, search_values)[2]\n",
    "n = select_data(my_table, search_column_name, search_values)[3]\n",
    "Z = select_data(my_table, search_column_name, search_values)[4]\n",
    "print (SURVEY,PROGRAM,HEALPIX, n, Z)\n",
    "\n",
    "for n, survey, program, healpix, Z, search_value in zip(n, SURVEY, PROGRAM, HEALPIX, Z, search_values):\n",
    "        #download the file from the given Target ID\n",
    "        target_url = f\"https://data.desi.lbl.gov/public/edr/spectro/redux/fuji/healpix/{survey}/{program}/{n}/{healpix}/coadd-{survey}-{program}-{healpix}.fits\"\n",
    "        \n",
    "        # Define the folder name and file name\n",
    "        folder_name = 'DESI_Downloads'\n",
    "        file_name = f\"coadd-{survey}-{program}-{healpix}.fits\"\n",
    "        print(search_value)\n",
    "\n",
    "\n",
    "        # Check if the folder exists, and create it if it doesn't\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "\n",
    "        # Check if the file exists in the folder\n",
    "        file_path = os.path.join(folder_name, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"{file_name} already exists in {folder_name}. No need to download.\")\n",
    "        else:\n",
    "            # File doesn't exist, download it\n",
    "            try:\n",
    "                response = requests.get(target_url)\n",
    "                if response.status_code == 200:\n",
    "                    with open(file_path, 'wb') as file:\n",
    "                        file.write(response.content)\n",
    "                    print(f\"{file_name} downloaded to {folder_name}.\")\n",
    "                else:\n",
    "                    print(f\"Failed to download {file_name}. Status code: {response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while downloading {file_name}: {str(e)}\")\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelength Overlap Regions Weighted Average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_var_weighted_average(flux1, ivar1, flux2, ivar2):\n",
    "    \"\"\"\n",
    "    Finds the inverse varience weighted average of two flux spectra\n",
    "    \n",
    "    \"\"\"\n",
    "    weight1 = 1 / ivar1\n",
    "    weight2 = 1 / ivar2\n",
    "    total_weight = weight1 + weight2\n",
    "    weighted_flux1 = flux1 * (weight1 / total_weight)\n",
    "    weighted_flux2 = flux2 * (weight2 / total_weight)\n",
    "    weighted_avg = weighted_flux1 + weighted_flux2\n",
    "    return weighted_avg\n",
    "\n",
    "def no_overlap_f(waveb,fluxb,waver,fluxr,wavez,fluxz):\n",
    "    \"\"\"\n",
    "    Isolates the flux and wavelength arrays of each band to non-overlapping wavelength sections\n",
    "    \n",
    "    \"\"\"\n",
    "    new_b_length = np.where(waveb<waver[0])\n",
    "    b_wave = waveb[new_b_length]\n",
    "    b_flux = fluxb[new_b_length]\n",
    "    new_r_length = np.where((waver>waveb[-1])&(waver<wavez[0]))\n",
    "    r_wave = waver[new_r_length]\n",
    "    r_flux = fluxr[new_r_length]\n",
    "    new_z_length = np.where(wavez>waver[-1])\n",
    "    z_wave = wavez[new_z_length]\n",
    "    z_flux = fluxz[new_z_length]\n",
    "\n",
    "    return b_wave,b_flux,r_wave,r_flux,z_wave,z_flux\n",
    "\n",
    "\n",
    "def overlap_av(wave1,wave2,flux1,flux2,ivar1,ivar2):\n",
    "    \"\"\"\n",
    "    Finds the overlap of two wavelength ranges.\n",
    "    Computes the inverse var weighted average flux and wavelength for th eoverlapping range \n",
    "    \n",
    "    \"\"\"\n",
    "    overlap_idx_1 = np.where(wave1 >= wave2[0]) \n",
    "    overlap_wave = wave1[overlap_idx_1]\n",
    "    overlap_flux_1 = flux1[overlap_idx_1]\n",
    "    overlap_ivar_1 = ivar1[overlap_idx_1]\n",
    "\n",
    "    overlap_idx_2 = np.where(wave2 <= wave1[-1]) \n",
    "    overlap_flux_2 = flux2[overlap_idx_2]\n",
    "    overlap_ivar_2 = ivar2[overlap_idx_2]\n",
    "    \n",
    "    overlap_av_flux = inv_var_weighted_average(overlap_flux_1,overlap_ivar_1,overlap_flux_2,overlap_ivar_2)\n",
    "\n",
    "    return overlap_av_flux, overlap_wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking functions\n",
    "\n",
    "# Ignore warnings due to spec_var=0\n",
    "warnings.filterwarnings(\"ignore\", message=\"divide by zero encountered in true_divide\")\n",
    "\n",
    "\n",
    "def get_spectra(table, column_name, search_values): \n",
    "    print('Number of spectra =', len(table))\n",
    "    # Get the Target IDs as a numpy array\n",
    "    column_data = table[column_name]\n",
    "\n",
    "    SURVEY, PROGRAM, HEALPIX, n_values = [], [], [], []\n",
    "    Z, RA, DEC, Source_ID = [], [], [], []\n",
    "\n",
    "\n",
    "    for search_value in search_values:\n",
    "        # Find the indices where the condition is met (value == search_value)\n",
    "        # This is only relevant if input is doen by search value and not selected table\n",
    "        indices = np.where(column_data == search_value)[0]\n",
    "\n",
    "        if len(indices) > 0:\n",
    "            # Find the corresponding Survey, program, healpix, Z , RA and Dec values\n",
    "            SURVEY.append(table['SURVEY'][indices[0]])\n",
    "            PROGRAM.append(table['PROGRAM'][indices[0]])\n",
    "            HEALPIX.append(table['HEALPIX'][indices[0]])\n",
    "            Z.append(table['Z'][indices[0]])\n",
    "            RA.append(table['TARGET_RA'][indices[0]]) \n",
    "            DEC.append(table['TARGET_DEC'][indices[0]])\n",
    "            Source_ID.append(table['TARGETID'][indices[0]])\n",
    "            HEALPIX_str = str(table['HEALPIX'][indices[0]])\n",
    "            n_str = HEALPIX_str[:3]\n",
    "            n_values.append(int(n_str))\n",
    "        else:\n",
    "            # Handle the case where the search value was not found\n",
    "            SURVEY.append(None)\n",
    "            PROGRAM.append(None)\n",
    "            HEALPIX.append(None)\n",
    "            n_values.append(None)\n",
    "            Z.append(None)   \n",
    "            RA.append(None)\n",
    "            DEC.append(None)\n",
    "            Source_ID.append(None)\n",
    "            \n",
    "    \n",
    "    z = np.array(Z)\n",
    "    RA = np.array(RA)\n",
    "    DEC = np.array(DEC)\n",
    "    id_spec = np.array(Source_ID)\n",
    "    wave_spec, flux_spec, sigma_spec = [], [], []\n",
    "    \n",
    "    for index, (survey, program, healpix, search_value) in enumerate(zip(SURVEY, PROGRAM, HEALPIX, search_values)):\n",
    "        \n",
    "        folder_name = 'DESI_Downloads'\n",
    "        file_name = f\"coadd-{survey}-{program}-{healpix}.fits\"\n",
    "        coadd_obj = desispec.io.read_spectra(f'{folder_name}/{file_name}')\n",
    "        coadd_tgts = coadd_obj.target_ids().data\n",
    "        # Selecting the particular spectra of the targetid\n",
    "        row = (coadd_tgts == search_value)\n",
    "        coadd_spec = coadd_obj[row] \n",
    "\n",
    "        # Inverse Vartiance weighted average for overlap\n",
    "        no_overlap = no_overlap_f(coadd_spec.wave['b'],coadd_spec.flux['b'][0],coadd_spec.wave['r'],coadd_spec.flux['r'][0],coadd_spec.wave['z'],coadd_spec.flux['z'][0])\n",
    "        overlap_br= overlap_av(coadd_spec.wave['b'],coadd_spec.wave['r'],coadd_spec.flux['b'][0],coadd_spec.flux['r'][0],coadd_spec.ivar['b'][0],coadd_spec.ivar['r'][0])\n",
    "        overlap_rz= overlap_av(coadd_spec.wave['r'],coadd_spec.wave['z'],coadd_spec.flux['r'][0],coadd_spec.flux['z'][0],coadd_spec.ivar['r'][0],coadd_spec.ivar['z'][0])\n",
    "        \n",
    "        \n",
    "        # Concaternating Spectra\n",
    "        flux_spectra = np.concatenate((no_overlap[1],overlap_br[0],no_overlap[3],overlap_rz[0],no_overlap[5]))\n",
    "        wave_spectra = np.concatenate((no_overlap[0],overlap_br[1],no_overlap[2],overlap_rz[1],no_overlap[4]))\n",
    "\n",
    "        # Using Desispec to get wavelengths, flux and sigma\n",
    "        wave = wave_spectra\n",
    "        wave = wave.flatten()\n",
    "        #flux = coadd_spec.flux['r'][0]\n",
    "        #flux = convolve(flux_spectra, Gaussian1DKernel(5))\n",
    "        #pick if i want to convolve or not\n",
    "        flux = flux_spectra\n",
    "        flux = flux.flatten()\n",
    "        sigma = (np.sqrt(1/coadd_spec.ivar['r']))\n",
    "        sigma = sigma.flatten()\n",
    "        if index % 2 == 0 and len(wave) > 0:\n",
    "                wave = wave[:-1]\n",
    "                flux = flux[:-1]\n",
    "                sigma = sigma[:-1]\n",
    "        sigma_spec.append(sigma)\n",
    "        wave_spec.append(wave)\n",
    "        flux_spec.append(flux)\n",
    "        \n",
    "    \n",
    "    wave_spec = np.array(wave_spec,dtype=object)\n",
    "    flux_spec = np.array(flux_spec,dtype=object)\n",
    "    sigma_spec = np.array(sigma_spec,dtype=object)\n",
    "    # alternatively tried wave_spec = wave_spec.tolist()\n",
    "\n",
    "    print('Number of spectra in wave spec=', len(wave_spec))\n",
    "    \n",
    "    return wave_spec, flux_spec, sigma_spec, z, RA, DEC, id_spec\n",
    "\n",
    "\n",
    "def get_stack(spec, zbins=None):# can add redshift ranges i.e zbins = [[0.0,0.1],[0.1,0.2]]\n",
    "    wave_spec, flux_spec, sigma_spec, z, RA, DEC, id_spec= spec\n",
    "    stack = sc.stack_spectra(wave_spec,flux_spec,sigma_spec,\n",
    "                               z, RA, DEC, zbins = zbins)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking - Save to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit here to pick class\n",
    "# LERG, HERG, RQAGN, SFG\n",
    "Overall_class = 'LERG'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "u_idx = len(crossmatch[crossmatch['Overall_class'] == f'{Overall_class}'])\n",
    "my_table = crossmatch[crossmatch['Overall_class'] == f'{Overall_class}'][0:u_idx]\n",
    "search_column_name = 'TARGETID'\n",
    "search_values = np.array(my_table[f'{search_column_name}'])\n",
    "\n",
    "\n",
    "tble_1 = crossmatch[(crossmatch['Z']>0.03) & (crossmatch['Z'] < 0.4)]\n",
    "my_table_1 = tble_1[tble_1['Overall_class'] == f'{Overall_class}']\n",
    "tble_2 = crossmatch[(crossmatch['Z']>0.4) & (crossmatch['Z'] < 0.9)]\n",
    "my_table_2 = tble_2[tble_2['Overall_class'] == f'{Overall_class}']\n",
    "tble_3 = crossmatch[(crossmatch['Z']>0.9) & (crossmatch['Z'] < 1.6)] #1.6 as this is where redrock starts to fail\n",
    "my_table_3 = tble_3[tble_3['Overall_class'] == f'{Overall_class}']\n",
    "\n",
    "tables = [my_table, my_table_1, my_table_2, my_table_3]\n",
    "stacks = []\n",
    "\n",
    "for table in tables:\n",
    "    search_values = np.array(table[f'{search_column_name}'])\n",
    "    spec = get_spectra(table, search_column_name, search_values)\n",
    "    stack = get_stack(spec)\n",
    "    stacks.append(stack)\n",
    "\n",
    "# Save stacks to CSV\n",
    "for i, stack in enumerate(stacks):\n",
    "    stack_df = pd.DataFrame({'wave_spec': stack['zbin=0']['wln'], 'flux_spec': stack['zbin=0']['flux']})\n",
    "    stack_df.to_csv(f'{Overall_class}_stack_{i}.csv', index=False)\n",
    "    print(f'Saved {Overall_class}_stack_{i}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Mass or sSFR in SFG also use below too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSo zbin_1_t is a list of 6 tables\\n\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate sSFR\n",
    "crossmatch['sSFR_cons'] = crossmatch['SFR_cons'] - crossmatch['Mass_cons']\n",
    "\n",
    "# Sort data by sSFR or mass\n",
    "var_bin = 'sSFR_cons'\n",
    "#var_bin = 'Mass_cons'\n",
    "crossmatch = crossmatch[np.array(np.argsort(crossmatch[f'{var_bin}']))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Overall_class = 'SFG'\n",
    "crossmatch = crossmatch[crossmatch['Overall_class'] == f'{Overall_class}']\n",
    "u_idx = len(crossmatch[crossmatch['Overall_class'] == f'{Overall_class}'])\n",
    "all_data = crossmatch[crossmatch['Overall_class'] == f'{Overall_class}'][0:u_idx]\n",
    "search_column_name = 'TARGETID'\n",
    "\n",
    "tble_1 = crossmatch[(crossmatch['Z']>0.03) & (crossmatch['Z'] < 0.4)]\n",
    "zbin_1 = tble_1[tble_1['Overall_class'] == f'{Overall_class}']\n",
    "tble_2 = crossmatch[(crossmatch['Z']>0.4) & (crossmatch['Z'] < 0.9)]\n",
    "zbin_2 = tble_2[tble_2['Overall_class'] == f'{Overall_class}']\n",
    "tble_3 = crossmatch[(crossmatch['Z']>0.9) & (crossmatch['Z'] < 1.6)] #1.6 as this is where redrock starts to fail\n",
    "zbin_3 = tble_3[tble_3['Overall_class'] == f'{Overall_class}']\n",
    "\n",
    "tables = [all_data, zbin_1, zbin_2, zbin_3]\n",
    "\n",
    "all_data_t = []\n",
    "zbin_1_t = []\n",
    "zbin_2_t = []\n",
    "zbin_3_t = []\n",
    "all_mass_max = []\n",
    "all_mass_min = []\n",
    "zbin_1_mass_max = []\n",
    "zbin_1_mass_min = []\n",
    "zbin_2_mass_max = []\n",
    "zbin_2_mass_min = []\n",
    "zbin_3_mass_max = []\n",
    "zbin_3_mass_min = []\n",
    "\n",
    "table_sizes = [6, 6, 4, 2]  # Number of bins for each table\n",
    "\n",
    "for i, table in enumerate(tables):\n",
    "    total_objects = len(table)\n",
    "    table_size = total_objects // table_sizes[i]\n",
    "    \n",
    "    for j in range(table_sizes[i]):\n",
    "        start_index = j * table_size\n",
    "        end_index = (j + 1) * table_size if j < table_sizes[i] - 1 else total_objects\n",
    "        \n",
    "        # Create a new table for the current segment\n",
    "        current_table = table[start_index:end_index]\n",
    "        \n",
    "        # Append the new table to the corresponding list based on the zbin\n",
    "        if table is all_data:\n",
    "            all_data_t.append(current_table)\n",
    "            all_mass_max.append(np.max(current_table['Mass_cons']))\n",
    "            all_mass_min.append(np.min(current_table['Mass_cons']))\n",
    "        elif table is zbin_1:\n",
    "            zbin_1_t.append(current_table)\n",
    "            zbin_1_mass_max.append(np.max(current_table['Mass_cons']))\n",
    "            zbin_1_mass_min.append(np.min(current_table['Mass_cons']))\n",
    "        elif table is zbin_2:\n",
    "            zbin_2_t.append(current_table)\n",
    "            zbin_2_mass_max.append(np.max(current_table['Mass_cons']))\n",
    "            zbin_2_mass_min.append(np.min(current_table['Mass_cons']))\n",
    "        elif table is zbin_3:\n",
    "            zbin_3_t.append(current_table)\n",
    "            zbin_3_mass_max.append(np.max(current_table['Mass_cons']))\n",
    "            zbin_3_mass_min.append(np.min(current_table['Mass_cons']))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "So zbin_1_t is a list of 6 tables\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks_zbin_1 = []\n",
    "\n",
    "for table in zbin_1_t:\n",
    "    search_values = np.array(table[f'{search_column_name}'])\n",
    "    spec = get_spectra(table, search_column_name, search_values)\n",
    "    stack = get_stack(spec)\n",
    "    stacks_zbin_1.append(stack)\n",
    "\n",
    "# Save stacks to CSV\n",
    "for i, stack in enumerate(stacks_zbin_1):\n",
    "    stack_df = pd.DataFrame({'wave_spec': stack['zbin=0']['wln'], 'flux_spec': stack['zbin=0']['flux']})\n",
    "    stack_df.to_csv(f'zbin_1_stack_{i}.csv', index=False)\n",
    "    print(f'Saved zbin_1_stack_{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks_zbin_2 = []\n",
    "\n",
    "for table in zbin_2_t:\n",
    "    search_values = np.array(table[f'{search_column_name}'])\n",
    "    spec = get_spectra(table, search_column_name, search_values)\n",
    "    stack = get_stack(spec)\n",
    "    stacks_zbin_2.append(stack)\n",
    "\n",
    "# Save stacks to CSV\n",
    "for i, stack in enumerate(stacks_zbin_2):\n",
    "    stack_df = pd.DataFrame({'wave_spec': stack['zbin=0']['wln'], 'flux_spec': stack['zbin=0']['flux']})\n",
    "    stack_df.to_csv(f'zbin_2_stack_{i}.csv', index=False)\n",
    "    print(f'Saved zbin_2_stack_{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks_zbin_3 = []\n",
    "\n",
    "for table in zbin_3_t:\n",
    "    search_values = np.array(table[f'{search_column_name}'])\n",
    "    spec = get_spectra(table, search_column_name, search_values)\n",
    "    stack = get_stack(spec)\n",
    "    stacks_zbin_3.append(stack)\n",
    "\n",
    "# Save stacks to CSV\n",
    "for i, stack in enumerate(stacks_zbin_3):\n",
    "    stack_df = pd.DataFrame({'wave_spec': stack['zbin=0']['wln'], 'flux_spec': stack['zbin=0']['flux']})\n",
    "    stack_df.to_csv(f'zbin_3_stack_{i}.csv', index=False)\n",
    "    print(f'Saved zbin_3_stack_{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in CSV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "LERG / HERG / RQAGN\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Overall_class = 'LERG' # Change this to HERG or RQAGN\n",
    "\n",
    "\n",
    "\n",
    "u_idx = len(crossmatch[crossmatch['Overall_class'] == f'{Overall_class}'])\n",
    "my_table = crossmatch[crossmatch['Overall_class'] == f'{Overall_class}'][0:u_idx]\n",
    "search_column_name = 'TARGETID'\n",
    "\n",
    "tble_1 = crossmatch[(crossmatch['Z']>0.03) & (crossmatch['Z'] < 0.4)]\n",
    "my_table_1 = tble_1[tble_1['Overall_class'] == f'{Overall_class}']\n",
    "tble_2 = crossmatch[(crossmatch['Z']>0.4) & (crossmatch['Z'] < 0.9)]\n",
    "my_table_2 = tble_2[tble_2['Overall_class'] == f'{Overall_class}']\n",
    "tble_3 = crossmatch[(crossmatch['Z']>0.9) & (crossmatch['Z'] < 1.6)] #1.6 as this is where redrock starts to fail\n",
    "my_table_3 = tble_3[tble_3['Overall_class'] == f'{Overall_class}']\n",
    "\n",
    "tables = [my_table, my_table_1, my_table_2, my_table_3]\n",
    "\n",
    "\n",
    "print(len(tble_1), len(my_table_1))\n",
    "\n",
    "stacks = []\n",
    "wln = []\n",
    "flux = []\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    stack_df = pd.read_csv(f'{Overall_class}_stack_{i}.csv')\n",
    "    stack = (stack_df['wave_spec'].values, stack_df['flux_spec'].values)\n",
    "    wln.append(stack[0])\n",
    "    flux.append(stack[1])\n",
    "    stacks.append(stack)\n",
    "\n",
    "\n",
    "wln_1, flux_1 = wln[1], flux[1]\n",
    "wln_2, flux_2 = wln[2], flux[2]\n",
    "wln_3, flux_3 = wln[3], flux[3]\n",
    "wln, flux = wln[0], flux[0]\n",
    "\n",
    "print(wln, flux)\n",
    "print(wln_1, flux_1)\n",
    "print(wln_2, flux_2)\n",
    "print(wln_3, flux_3)\n",
    "\n",
    "def renorm(flux, wln, wln_min, wln_max):\n",
    "    \"\"\"\n",
    "    Normalizes the flux to the median wavelength in the specified range\n",
    "    \"\"\"\n",
    "    indices = np.where((wln >= wln_min) & (wln <= wln_max))\n",
    "\n",
    "    flux_norm = flux / np.median(flux[indices])\n",
    "    \n",
    "    return flux_norm\n",
    "\n",
    "wln_min = 4500\n",
    "wln_max = 4700\n",
    "\n",
    "flux_1_norm = renorm(flux_1, wln_1, wln_min, wln_max)\n",
    "flux_2_norm = renorm(flux_2, wln_2, wln_min, wln_max)\n",
    "flux_3_norm = renorm(flux_3, wln_3, wln_min, wln_max)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Add in some bounds to remove the upper and lower 10% of each spectra as noise reduction\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def bounds(stack_array):\n",
    "        bound = 0.1\n",
    "        l_bound = len(stack_array)*bound\n",
    "        u_bound = len(stack_array)-(len(stack_array)*bound)\n",
    "\n",
    "        return int(l_bound), int(u_bound)\n",
    "\n",
    "\n",
    "st1 = bounds(wln_1)\n",
    "st2 = bounds(wln_2)\n",
    "st3 = bounds(wln_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"  \n",
    "\n",
    "Read's CSV files back in - SFG\n",
    "\n",
    "*** Need to change the name of what you are reading in depending on which stacks you want **\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def renorm(flux, wln, wln_min, wln_max):\n",
    "    \"\"\"\n",
    "    Normalizes the flux to the median wavelength in the specified range\n",
    "    \"\"\"\n",
    "    indices = np.where((wln >= wln_min) & (wln <= wln_max))\n",
    "\n",
    "    flux_norm = flux / np.median(flux[indices])\n",
    "    \n",
    "    return flux_norm\n",
    "\n",
    "wln_min = 4800\n",
    "wln_max = 5000\n",
    "\n",
    "all_data_stacks = []\n",
    "all_data_wln = []\n",
    "all_data_flux = []\n",
    "all_data_flux_renorm = []\n",
    "\n",
    "zbin_1_stacks = []\n",
    "zbin_1_wln = []\n",
    "zbin_1_flux = []    \n",
    "zbin_1_flux_renorm = []\n",
    "\n",
    "zbin_2_stacks = []\n",
    "zbin_2_wln = []\n",
    "zbin_2_flux = []\n",
    "zbin_2_flux_renorm = []\n",
    "\n",
    "zbin_3_stacks = []\n",
    "zbin_3_wln = []\n",
    "zbin_3_flux = []\n",
    "zbin_3_flux_renorm = []\n",
    "\n",
    "for i in range(6):\n",
    "    #all_data_stack_df = pd.read_csv(f'all_data_stack_{i}.csv')\n",
    "    #all_data_stack = (all_data_stack_df['wave_spec'].values, all_data_stack_df['flux_spec'].values)\n",
    "    #all_data_stacks.append(all_data_stack)\n",
    "    #all_data_wln.append(all_data_stack[0])\n",
    "    #all_data_flux.append(all_data_stack[1])\n",
    "    \n",
    "    zbin_1_stack_df = pd.read_csv(f'zbin_1_stack_s{i}.csv') # Change here\n",
    "    zbin_1_stack = (zbin_1_stack_df['wave_spec'].values, zbin_1_stack_df['flux_spec'].values)\n",
    "    zbin_1_stacks.append(zbin_1_stack)\n",
    "    zbin_1_wln.append(zbin_1_stack[0])\n",
    "    zbin_1_flux.append(zbin_1_stack[1])\n",
    "    zbin_1_flux_renorm.append(renorm(zbin_1_stack[1], zbin_1_stack[0], wln_min, wln_max))\n",
    "    \n",
    "for i in range(4):\n",
    "    zbin_2_stack_df = pd.read_csv(f'zbin_2_stack_s{i}.csv') # Change here\n",
    "    zbin_2_stack = (zbin_2_stack_df['wave_spec'].values, zbin_2_stack_df['flux_spec'].values)\n",
    "    zbin_2_stacks.append(zbin_2_stack)\n",
    "    zbin_2_wln.append(zbin_2_stack[0])\n",
    "    zbin_2_flux.append(zbin_2_stack[1])\n",
    "    zbin_2_flux_renorm.append(renorm(zbin_2_stack[1], zbin_2_stack[0], wln_min, wln_max))\n",
    "    \n",
    "for i in range(2):\n",
    "    zbin_3_stack_df = pd.read_csv(f'zbin_3_stack_s{i}.csv') # Change here\n",
    "    zbin_3_stack = (zbin_3_stack_df['wave_spec'].values, zbin_3_stack_df['flux_spec'].values)\n",
    "    zbin_3_stacks.append(zbin_3_stack)\n",
    "    zbin_3_wln.append(zbin_3_stack[0])\n",
    "    zbin_3_flux.append(zbin_3_stack[1])\n",
    "    zbin_3_flux_renorm.append(renorm(zbin_3_stack[1], zbin_3_stack[0], wln_min, wln_max))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equivalent Width Calculations (only applied to SFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "Continuum fit\n",
    "\n",
    "Points to consider:\n",
    "- Could change the region of wavelength to fit the continuum\n",
    "- Could just fit polynomial to the continuum\n",
    "- When exculing region need to cosider the N2 peaks\n",
    "\n",
    "\n",
    "\"\"\"\"\"\n",
    "\n",
    "\n",
    "def fit_continuum(wln, flux, contin_min, contin_max, exclude_region, exclude_width):\n",
    "    \"\"\"\n",
    "    Fit a continuum to the spectrum\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wln : numpy.ndarray\n",
    "        Wavelength array\n",
    "\n",
    "    flux : numpy.ndarray\n",
    "        Flux array\n",
    "\n",
    "    contin_min : float\n",
    "        Minimum wavelength to fit the continuum\n",
    "\n",
    "    contin_max : float\n",
    "        Maximum wavelength to fit the continuum\n",
    "\n",
    "    exclude_region : float, optional\n",
    "        Central wavelength of emission line to exclude from the continuum fit\n",
    "\n",
    "    exclude_width : float, optional\n",
    "        Width of the emission line to exclude from the continuum fit\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    y_continuum_fitted : numpy.ndarray\n",
    "        Fitted continuum values\n",
    "    \n",
    "    wln_region : numpy.ndarray\n",
    "        Wavelength array of the region to fit the continuum\n",
    "    \n",
    "    flux_region : numpy.ndarray\n",
    "        Flux array of the region to fit the continuum\n",
    "\n",
    "    spectrum : specutils.Spectrum1D\n",
    "        Spectrum1D object of the region to fit the continuum\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    flux_region = flux[(wln >= contin_min) & (wln <= contin_max)]\n",
    "    wln_region = wln[(wln >= contin_min) & (wln <= contin_max)]\n",
    "\n",
    "\n",
    "    # Create a Spectrum1D object from the spectra\n",
    "    spectrum = Spectrum1D(flux=flux_region*u.Unit('erg/s/cm^2/AA'), spectral_axis=wln_region*u.AA)\n",
    "\n",
    "    # Define the region to exclude (H alpha peak)\n",
    "    exclude_region = SpectralRegion(exclude_region*u.AA - exclude_width*u.AA, exclude_region*u.AA + exclude_width*u.AA)\n",
    "\n",
    "    # Fit a generic continuum model to the spectrum, excluding the H alpha peak\n",
    "    with warnings.catch_warnings():  # Ignore warnings\n",
    "        warnings.simplefilter('ignore')\n",
    "        g1_fit = fit_generic_continuum(spectrum, exclude_regions=[exclude_region])\n",
    "\n",
    "    # Generate the fitted continuum values\n",
    "    y_continuum_fitted = g1_fit(wln_region*u.AA)\n",
    "\n",
    "    return y_continuum_fitted, wln_region, flux_region, spectrum\n",
    "\n",
    "\"\"\"   \n",
    "Get continuum Normalised and continuum subtracted spectra\n",
    "\n",
    "Do I want to use the full spectrum or just the section I fitted the continuum to?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def spec_norm(spectrum, cont):\n",
    "    \"\"\"\n",
    "    Normalise the spectrum by dividing by the continuum\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectrum : numpy.ndarray\n",
    "        Spectrum Values\n",
    "        (output [2] from continuum fit function)\n",
    "\n",
    "    cont : numpy.ndarray\n",
    "        Fitted continuum values\n",
    "        (output [0] from fit continuum function)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    flux_norm.spectral_axis: numpy.ndarray\n",
    "        Normalised wavelength values\n",
    "    \n",
    "    flux_norm.flux: numpy.ndarray\n",
    "        Normalised flux values\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    flux_norm = spectrum / cont\n",
    "\n",
    "    return flux_norm.spectral_axis, flux_norm.flux\n",
    "\n",
    "def spec_sub(spectrum, cont):\n",
    "    \"\"\"\n",
    "    Subtract the continuum from the spectrum\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectrum : numpy.ndarray\n",
    "        Spectrum Values\n",
    "        (output [2] from continuum fit function)\n",
    "\n",
    "    cont : numpy.ndarray\n",
    "        Fitted continuum values\n",
    "        (output [0] from fit continuum function)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    flux_sub.spectral_axis: numpy.ndarray\n",
    "        Subtracted wavelength values\n",
    "    \n",
    "    flux_sub.flux: numpy.ndarray\n",
    "        Subtracted flux values\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    flux_sub = spectrum - cont\n",
    "\n",
    "    return flux_sub.spectral_axis, flux_sub.flux\n",
    "\n",
    "\n",
    "\n",
    "def EW_integral(wln, flux, cont,wln_emissionline, line_width):\n",
    "    \"\"\"\n",
    "    Calculate the equivalent width of a spectrum\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wln : numpy.ndarray\n",
    "        Wavelength array\n",
    "\n",
    "    flux : numpy.ndarray\n",
    "        Flux array\n",
    "\n",
    "    cont : numpy.ndarray\n",
    "        Fitted continuum values\n",
    "\n",
    "    wln_emissionline : float\n",
    "        Wavelength of the emission line\n",
    "    \n",
    "    line_width : float\n",
    "        Width of the emission line\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    EW : float\n",
    "        Equivalent width of the spectrum\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the region to integrate\n",
    "    region = (wln >= wln_emissionline-line_width/2) & (wln <= wln_emissionline+line_width/2)\n",
    "\n",
    "    # Calculate the equivalent width\n",
    "    EW = np.trapz(1 - (flux[region] / cont[region]), wln[region])\n",
    "\n",
    "    return EW\n",
    "\n",
    "\"\"\"    \n",
    "Fit Gaussian to H alpha peak\n",
    "Find the Equivalent Width using FWHM*Amplitude\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from astropy.modeling import models\n",
    "from astropy import units as u\n",
    "from specutils.spectra import Spectrum1D\n",
    "from specutils.fitting import fit_lines\n",
    "\n",
    "\n",
    "def fit_gaussian(wln_sub, flux_sub, wln_emissionline, line_width):\n",
    "\n",
    "    \"\"\"\n",
    "    Fit a Gaussian to the H alpha peak\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wln_sub : numpy.ndarray\n",
    "        Wavelength array of the continuum subtracted spectrum\n",
    "    \n",
    "    flux_sub : numpy.ndarray\n",
    "        Flux array of the continuum subtracted spectrum\n",
    "    \n",
    "    wln_emissionline : float\n",
    "        Wavelength of the emission line\n",
    "    \n",
    "    line_width : float\n",
    "        Width of the emission line\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_fit : numpy.ndarray\n",
    "        Fitted Gaussian values\n",
    "    \n",
    "    fwhm : float\n",
    "        Full width at half maximum of the fitted Gaussian\n",
    "    \n",
    "    amplitude : float\n",
    "        Amplitude of the fitted Gaussian\n",
    "    \n",
    "    equivalent_width : float\n",
    "        Equivalent width of the fitted Gaussian\n",
    "\n",
    "    wln_sub[region] : numpy.ndarray\n",
    "        Wavelength array of the region to fit the Gaussian\n",
    "\n",
    "    flux_sub[region] : numpy.ndarray\n",
    "        Flux array of the region to fit the Gaussian\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Define the region to fit the Gaussian\n",
    "    region = (wln_sub >= wln_emissionline-line_width/2) & (wln_sub <= wln_emissionline+line_width/2)\n",
    "\n",
    "    # Create a Spectrum1D object covering emissionn line width\n",
    "    spectrum_line = Spectrum1D(flux=flux_sub[region]*u.Unit('erg/s/cm^2/AA'), \n",
    "                    spectral_axis=wln_sub[region]*u.AA)\n",
    "    \n",
    "    # Fit a Gaussian model to the region of interest\n",
    "    g_init = models.Gaussian1D(amplitude=np.max(spectrum_line.flux), mean=np.mean(spectrum_line.spectral_axis), stddev=1*u.AA)\n",
    "    g_fit = fit_lines(spectrum_line, g_init)\n",
    "\n",
    "    # Generate the fitted Gaussian values\n",
    "    y_fit = g_fit(wln_sub[region]*u.AA)\n",
    "\n",
    "    fwhm = g_fit.fwhm\n",
    "\n",
    "    amplitude = g_fit.amplitude\n",
    "\n",
    "    # Calculate the equivalent width \n",
    "    equivalent_width = fwhm*amplitude\n",
    "\n",
    "    return y_fit, fwhm, amplitude, equivalent_width,  wln_sub[region], flux_sub[region]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H alpha for SFG\n",
    "\n",
    "# naming used here is silly - make it more logical!\n",
    "\n",
    "\n",
    "\n",
    "wln_emissionline = 6562.8\n",
    "line_width = 20\n",
    "\n",
    "ew_int_2 = []\n",
    "ew_spec_2 = []\n",
    "ew_gauss_2 = []\n",
    "\n",
    "for i in range(4):\n",
    "    y_continuum_fit, wln_region, flux_region, spectrum = fit_continuum(zbin_2_wln[i], zbin_2_flux[i], 6400, 6700, exclude_region = 6563, exclude_width = 100) # needs to be a wider gap excluded to exclude the N2 peaks\n",
    "    flux_norm = spec_norm(spectrum, y_continuum_fit)\n",
    "    flux_sub = spec_sub(spectrum, y_continuum_fit)\n",
    "    eq_width_integral = EW_integral(wln_region, flux_region, y_continuum_fit.value, wln_emissionline, line_width)\n",
    "    spectrum_norm = Spectrum1D(flux=flux_norm[1], spectral_axis=flux_norm[0])\n",
    "    eq_width_spec = equivalent_width(spectrum_norm, regions=SpectralRegion((wln_emissionline-line_width/2)*u.AA, (wln_emissionline+line_width/2)*u.AA))\n",
    "    y_fit, fwhm, amplitude, eq_width_gauss, wln_sub, flux_sub = fit_gaussian(flux_sub[0].value, flux_sub[1].value, wln_emissionline, line_width)\n",
    "    ew_int_2.append(abs(eq_width_integral))\n",
    "    ew_spec_2.append(abs(eq_width_spec.value))\n",
    "    ew_gauss_2.append(abs(eq_width_gauss.value))\n",
    "\n",
    "print(ew_int_2)\n",
    "print(ew_spec_2)\n",
    "print(ew_gauss_2)\n",
    "\n",
    "\n",
    "ew_int_1 = []\n",
    "ew_spec_1 = []\n",
    "ew_gauss_1 = []\n",
    "\n",
    "for i in range(6):\n",
    "    y_continuum_fit, wln_region, flux_region, spectrum = fit_continuum(zbin_1_wln[i], zbin_1_flux[i], 6400, 6700, exclude_region = 6563, exclude_width = 100) # needs to be a wider gap excluded to exclude the N2 peaks\n",
    "    flux_norm = spec_norm(spectrum, y_continuum_fit)\n",
    "    flux_sub = spec_sub(spectrum, y_continuum_fit)\n",
    "    eq_width_integral = EW_integral(wln_region, flux_region, y_continuum_fit.value, wln_emissionline, line_width)\n",
    "    spectrum_norm = Spectrum1D(flux=flux_norm[1], spectral_axis=flux_norm[0])\n",
    "    eq_width_spec = equivalent_width(spectrum_norm, regions=SpectralRegion((wln_emissionline-line_width/2)*u.AA, (wln_emissionline+line_width/2)*u.AA))\n",
    "    y_fit, fwhm, amplitude, eq_width_gauss, wln_sub, flux_sub = fit_gaussian(flux_sub[0].value, flux_sub[1].value, wln_emissionline, line_width)\n",
    "    ew_int_1.append(abs(eq_width_integral))\n",
    "    ew_spec_1.append(abs(eq_width_spec.value))\n",
    "    ew_gauss_1.append(abs(eq_width_gauss.value))\n",
    "\n",
    "print(ew_int_1)\n",
    "print(ew_spec_1)\n",
    "print(ew_gauss_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## O[II] for SFG\n",
    "\n",
    "\n",
    "wln_emissionline = 3727\n",
    "line_width = 20\n",
    "from specutils.analysis import equivalent_width\n",
    "\n",
    "ew_int_3 = []\n",
    "ew_spec_3 = []\n",
    "ew_gauss_3 = []\n",
    "\n",
    "for i in range(4):\n",
    "    y_continuum_fit, wln_region, flux_region, spectrum = fit_continuum(zbin_2_wln[i], zbin_2_flux[i], 3300, 4200, exclude_region = 6563, exclude_width = 100) # needs to be a wider gap excluded to exclude the N2 peaks\n",
    "    flux_norm = spec_norm(spectrum, y_continuum_fit)\n",
    "    flux_sub = spec_sub(spectrum, y_continuum_fit)\n",
    "    eq_width_integral = EW_integral(wln_region, flux_region, y_continuum_fit.value, wln_emissionline, line_width)\n",
    "    spectrum_norm = Spectrum1D(flux=flux_norm[1], spectral_axis=flux_norm[0])\n",
    "    eq_width_spec = equivalent_width(spectrum_norm, regions=SpectralRegion((wln_emissionline-line_width/2)*u.AA, (wln_emissionline+line_width/2)*u.AA))\n",
    "    y_fit, fwhm, amplitude, eq_width_gauss, wln_sub, flux_sub = fit_gaussian(flux_sub[0].value, flux_sub[1].value, wln_emissionline, line_width)\n",
    "    ew_int_3.append(abs(eq_width_integral))\n",
    "    ew_spec_3.append(abs(eq_width_spec.value))\n",
    "    ew_gauss_3.append(abs(eq_width_gauss.value))\n",
    "\n",
    "print(ew_int_3)\n",
    "print(ew_spec_3)\n",
    "print(ew_gauss_3)\n",
    "\n",
    "\n",
    "ew_int_4 = []\n",
    "ew_spec_4 = []\n",
    "ew_gauss_4 = []\n",
    "\n",
    "for i in range(6):\n",
    "    y_continuum_fit, wln_region, flux_region, spectrum = fit_continuum(zbin_1_wln[i], zbin_1_flux[i], 3300, 4200, exclude_region = 6563, exclude_width = 100) # needs to be a wider gap excluded to exclude the N2 peaks\n",
    "    flux_norm = spec_norm(spectrum, y_continuum_fit)\n",
    "    flux_sub = spec_sub(spectrum, y_continuum_fit)\n",
    "    eq_width_integral = EW_integral(wln_region, flux_region, y_continuum_fit.value, wln_emissionline, line_width)\n",
    "    spectrum_norm = Spectrum1D(flux=flux_norm[1], spectral_axis=flux_norm[0])\n",
    "    eq_width_spec = equivalent_width(spectrum_norm, regions=SpectralRegion((wln_emissionline-line_width/2)*u.AA, (wln_emissionline+line_width/2)*u.AA))\n",
    "    y_fit, fwhm, amplitude, eq_width_gauss, wln_sub, flux_sub = fit_gaussian(flux_sub[0].value, flux_sub[1].value, wln_emissionline, line_width)\n",
    "    ew_int_4.append(abs(eq_width_integral))\n",
    "    ew_spec_4.append(abs(eq_width_spec.value))\n",
    "    ew_gauss_4.append(abs(eq_width_gauss.value))\n",
    "\n",
    "print(ew_int_4)\n",
    "print(ew_spec_4)\n",
    "print(ew_gauss_4)\n",
    "\n",
    "ew_int_5 = []   \n",
    "ew_spec_5 = []\n",
    "ew_gauss_5 = []\n",
    "\n",
    "for i in range(2):\n",
    "    y_continuum_fit, wln_region, flux_region, spectrum = fit_continuum(zbin_3_wln[i], zbin_3_flux[i], 3300, 4200, exclude_region = 6563, exclude_width = 100) # needs to be a wider gap excluded to exclude the N2 peaks\n",
    "    flux_norm = spec_norm(spectrum, y_continuum_fit)\n",
    "    flux_sub = spec_sub(spectrum, y_continuum_fit)\n",
    "    eq_width_integral = EW_integral(wln_region, flux_region, y_continuum_fit.value, wln_emissionline, line_width)\n",
    "    spectrum_norm = Spectrum1D(flux=flux_norm[1], spectral_axis=flux_norm[0])\n",
    "    eq_width_spec = equivalent_width(spectrum_norm, regions=SpectralRegion((wln_emissionline-line_width/2)*u.AA, (wln_emissionline+line_width/2)*u.AA))\n",
    "    y_fit, fwhm, amplitude, eq_width_gauss, wln_sub, flux_sub = fit_gaussian(flux_sub[0].value, flux_sub[1].value, wln_emissionline, line_width)\n",
    "    ew_int_5.append(abs(eq_width_integral))\n",
    "    ew_spec_5.append(abs(eq_width_spec.value))\n",
    "    ew_gauss_5.append(abs(eq_width_gauss.value))\n",
    "\n",
    "print(ew_int_5)\n",
    "print(ew_spec_5)\n",
    "print(ew_gauss_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Stacked Spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LERG / HERG / RQAGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create a PDF file to save the plots\n",
    "pdf_filename = f'DESI-{Overall_class}-stack_Final.pdf'\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "        fig, ax = plt.subplots(figsize=(16, 5))\n",
    "        ax.plot(wln,flux, color='blue', alpha=0.5,label = f'DESI Raw Stack, LOFAR Class {Overall_class}')\n",
    "        ax.plot(wln,convolve(flux, Gaussian1DKernel(5)), color='black', alpha=1, label = f'DESI Smoothed Gaussian Stack, LOFAR Class {Overall_class}')\n",
    "        ax.set_ylabel('$F_{\\lambda}$ [$10^{-17} erg\\ s^{-1}\\ cm^{-2}\\ \\AA^{-1}$]')\n",
    "        ax.set_xlabel('Rest-frame wavelength, $\\lambda$ [$\\AA$]')\n",
    "        ax.set_xlim(1200,8000)\n",
    "        ax.set_ylim(-2,7)\n",
    "        ax.set_xticks(range(1200, 8001, 500))\n",
    "        ax.set_yticks(range(-2, 7, 1))\n",
    "        ax.tick_params(axis='both', which='both', labelsize=12, direction = 'in')\n",
    "        ax.minorticks_on()\n",
    "        ax.legend(fontsize='large', loc = 'upper right')\n",
    "        ax.xaxis.label.set_size(15)\n",
    "        ax.yaxis.label.set_size(15)\n",
    "\n",
    "     # Save the current plot to the PDF file\n",
    "        pdf.savefig(fig)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# All the plots will be saved in the PDF file\n",
    "print(f'All plots saved in {pdf_filename}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PDF file to save the plots\n",
    "pdf_filename = f'DESI-{Overall_class}-stacked-zbin-plots-0.1cut-final.pdf'\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "        fig, ax = plt.subplots(figsize=(16, 5))\n",
    "        ax.plot(wln_1[st1[0]:st1[1]],flux_1_norm[st1[0]:st1[1]], label = f'Raw Stack: 0.03<z<0.4', color='blue', alpha=0.5)\n",
    "        ax.plot(wln_1[st1[0]:st1[1]],convolve(flux_1_norm, Gaussian1DKernel(5))[st1[0]:st1[1]], color='black', alpha=1)\n",
    "        ax.plot(wln_2[st2[0]:st2[1]],flux_2_norm[st2[0]:st2[1]], label = f'Raw Stack: 0.4<z<0.9', color='green', alpha=0.5)\n",
    "        ax.plot(wln_2[st2[0]:st2[1]],convolve(flux_2_norm, Gaussian1DKernel(5))[st2[0]:st2[1]], color='black', alpha=1)\n",
    "        ax.plot(wln_3[st3[0]:st3[1]],flux_3_norm[st3[0]:st3[1]], label = f'Raw Stack: 0.9<z<1.6', color='red', alpha=0.5)\n",
    "        ax.plot(wln_3[st3[0]:st3[1]],convolve(flux_3_norm, Gaussian1DKernel(5))[st3[0]:st3[1]], color='black', alpha=1, label = f'Smoothed Gaussian Stacks, \\u03C3=5 ')\n",
    "        ax.set_ylabel('$F_{\\lambda, Norm}$ ')\n",
    "        ax.set_xlabel('Rest-frame wavelength, $\\lambda$ [$\\AA$]')\n",
    "        ax.set_xlim(1800,8000)\n",
    "        ax.set_ylim(-0.3,1.5)\n",
    "        ax.set_xticks(range(1800, 8001, 500))\n",
    "        ax.set_yticks(range(0, 2, 1))\n",
    "        ax.tick_params(axis='both', which='both', labelsize=12, direction = 'in')\n",
    "        ax.minorticks_on()\n",
    "        ax.legend(fontsize='large', loc = 'upper left')\n",
    "        ax.xaxis.label.set_size(15)\n",
    "        ax.yaxis.label.set_size(15)\n",
    "        fig.suptitle(f'DESI Spectra Stacks, LOFAR Class: {Overall_class}', fontsize=15)\n",
    "\n",
    "     # Save the current plot to the PDF file\n",
    "        pdf.savefig(fig)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# After the loop, all the plots will be saved in the PDF file\n",
    "print(f'All plots saved in {pdf_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "Will need to change the x and y lims depending on the class being stcaked\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Create a PDF file to save the plots\n",
    "pdf_filename = f'DESI-{Overall_class}-stacked-zbin-plots-0.1cut_split_final.pdf'\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "    # Create a 1x3 grid of subplots with no spacing between plots\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(33,8), sharey=True, sharex=False, gridspec_kw={'wspace': 0})\n",
    "    \n",
    "    # Plot for column 1 (flux_1)\n",
    "    axs[0].plot(wln_1[st1[0]:st1[1]], flux_1_norm[st1[0]:st1[1]], label=f'Raw Stack', color='blue', alpha=0.5)\n",
    "    axs[0].plot(wln_1[st1[0]:st1[1]], convolve(flux_1_norm, Gaussian1DKernel(5))[st1[0]:st1[1]], color='black', alpha=1, label=f'Smoothed Gaussian Stack, \\u03C3=5 ')\n",
    "    axs[0].set_xlim(3400, 8400)\n",
    "    axs[0].set_xticks(range(3400, 8399, 1000))\n",
    "    axs[0].set_title('0.03<z<0.4', fontsize=20)\n",
    "    \n",
    "    # Plot for column 2 (flux_2)\n",
    "    axs[1].plot(wln_2[st2[0]:st2[1]], flux_2_norm[st2[0]:st2[1]], label=f'Raw Stack', color='green', alpha=0.5)\n",
    "    axs[1].plot(wln_2[st2[0]:st2[1]], convolve(flux_2_norm, Gaussian1DKernel(5))[st2[0]:st2[1]], color='black', alpha=1, label=f'Smoothed Gaussian Stack, \\u03C3=5 ')\n",
    "    axs[1].set_xlim(2500, 6400)\n",
    "    axs[1].set_xticks(range(2500, 6401, 1000))\n",
    "    axs[1].set_title('0.4<z<0.9', fontsize=20)\n",
    "\n",
    "    # Plot for column 3 (flux_3)\n",
    "    axs[2].plot(wln_3[st3[0]:st3[1]], flux_3_norm[st3[0]:st3[1]], label=f'Raw Stack', color='red', alpha=0.5)\n",
    "    axs[2].plot(wln_3[st3[0]:st3[1]], convolve(flux_3_norm, Gaussian1DKernel(5))[st3[0]:st3[1]], color='black', alpha=1, label=f'Smoothed Gaussian Stack, \\u03C3=5 ')\n",
    "    axs[2].set_xlim(1800, 4300)\n",
    "    axs[2].set_xticks(range(1800, 4301, 500))\n",
    "    axs[2].set_title('0.9<z<1.6', fontsize=20)\n",
    "\n",
    "    # Customize common settings for all subplots\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.set_ylabel('$F_{\\lambda, Norm}$ ')\n",
    "        ax.set_xlabel('Rest-frame wavelength, $\\lambda$ [$\\AA$]')\n",
    "        #ax.set_xlim(1100, 8500)\n",
    "        ax.set_ylim(-0.3, 1.5)\n",
    "        #ax.set_xticks(range(1100, 8501, 1000))  # Adjust the tick values\n",
    "        ax.set_yticks(range(0, 2, 1))\n",
    "        ax.tick_params(axis='both', which='both', labelsize=12, direction='in')\n",
    "        ax.minorticks_on()\n",
    "        if i != 0:\n",
    "            ax.set_ylabel('')\n",
    "        ax.legend(fontsize='large', loc='upper left')  # Adjust the legend location\n",
    "        ax.xaxis.label.set_size(15)\n",
    "        ax.yaxis.label.set_size(15)\n",
    "    \n",
    "    fig.suptitle(f'DESI Spectra Stacks, LOFAR Class: {Overall_class}', fontsize=25)\n",
    "\n",
    "    \n",
    "    # Save the current plot to the PDF file\n",
    "    pdf.savefig(fig)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# After the loop, all the plots will be saved in the PDF file\n",
    "print(f'All plots saved in {pdf_filename}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "font = 20\n",
    "print('Range for All data:', all_mass_min,all_mass_max)\n",
    "print('Range for zbin_1:', zbin_1_mass_min,zbin_1_mass_max)\n",
    "print('Range for zbin_2:', zbin_2_mass_min,zbin_2_mass_max)\n",
    "print('Range for zbin_3:', zbin_3_mass_min,zbin_3_mass_max)\n",
    "\n",
    "\n",
    "\n",
    "# Plotting for zbin 1\n",
    "fig, axes = plt.subplots(6, 3, figsize=(30, 30), sharex=False, sharey=False)\n",
    "\n",
    "\"\"\"\n",
    "****THIS PLOT IS CURRENTLY RENORMALISED TO 4800-5000 RANGE***\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the alpha values for each row\n",
    "alpha_values = [0.2, 0.3, 0.4, 0.5, 0.7, 1.0][::-1]\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "        axes[5-i, 0].set_xlabel('Rest-frame wavelength, $\\lambda$ [$\\AA$]', fontsize= font)\n",
    "        axes[5-i, 0].set_ylabel('$F_{\\lambda, Norm}$ ', fontsize= font)\n",
    "        #axes[5-i, 0].legend(fontsize=12, loc='upper left')\n",
    "        axes[5-i, 0].set_xlim(2700, 8000)\n",
    "        axes[5-i, 0].set_ylim(-0.3, 4.5)\n",
    "        axes[5-i, 0].tick_params(axis='both', which='major', labelsize=font) \n",
    "        text_combined = (f'Log (M/M$\\odot$) = {zbin_1_mass_min[i]:.2f}:{zbin_1_mass_max[i]:.2f}\\n' +\n",
    "                    f'H$\\\\alpha$ Equivalent Width [$\\AA$] = {abs(ew_int_1[i]):.2f}\\n' +\n",
    "                    f'[OII] Equivalent Width [$\\AA$] = {abs(ew_int_4[i]):.2f}')\n",
    "        axes[5-i, 0].text(0.02, 0.95, text_combined, transform=axes[5-i, 0].transAxes, fontsize=10,\n",
    "                    verticalalignment='top', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'))\n",
    "        \n",
    "        \n",
    "        if i != 0:\n",
    "            axes[5-i, 0].plot(zbin_1_wln[i], zbin_1_flux_renorm[i], color='dodgerblue', alpha=alpha_values[i])\n",
    "            axes[5-i, 0].plot(zbin_1_wln[i], convolve(zbin_1_flux_renorm[i], Gaussian1DKernel(5)),color='black', alpha=1.0)\n",
    "            axes[5-i, 0].plot(zbin_1_wln[0], convolve(zbin_1_flux_renorm[0], Gaussian1DKernel(5)),color='black',linestyle = '--', alpha=0.6)\n",
    "        else:\n",
    "            axes[5-i, 0].plot(zbin_1_wln[i], zbin_1_flux_renorm[i], \n",
    "                                label = f'Raw Stacks  0.03<z<0.4', color='dodgerblue', alpha=alpha_values[i])\n",
    "            axes[5-i, 0].plot(zbin_1_wln[i], convolve(zbin_1_flux_renorm[i], Gaussian1DKernel(5)),\n",
    "                                color='black', alpha=1.0)\n",
    "            axes[5-i, 0].plot(zbin_1_wln[0], convolve(zbin_1_flux_renorm[0], Gaussian1DKernel(5)),\n",
    "                                color='black',linestyle = '--', alpha=0.6)\n",
    "            \n",
    "\n",
    "# Plotting for zbin 2\n",
    "for i in range(4):\n",
    "    axes[5-i, 1].set_xlabel('Rest-frame wavelength, $\\lambda$ [$\\AA$]', fontsize= font)\n",
    "    axes[5-i, 1].set_ylabel('$F_{\\lambda, Norm}$ ', fontsize= font)\n",
    "    #axes[5-i, 1].legend(fontsize=12, loc='upper left')\n",
    "    axes[5-i, 1].set_xlim(2000, 7000)\n",
    "    axes[5-i, 1].set_ylim(-0.3, 4.5)\n",
    "    axes[5-i, 1].tick_params(axis='both', which='major', labelsize=font)  \n",
    "    text_combined = (f'Log (M/M$\\odot$) = {zbin_2_mass_min[i]:.2f}:{zbin_2_mass_max[i]:.2f}\\n' +\n",
    "                 f'H$\\\\alpha$ Equivalent Width [$\\AA$] = {abs(ew_int_2[i]):.2f}\\n'+\n",
    "                 f'[OII] Equivalent Width [$\\AA$] = {abs(ew_int_3[i]):.2f}')\n",
    "    axes[5-i, 1].text(0.02, 0.95, text_combined, transform=axes[5-i, 1].transAxes, fontsize=10,\n",
    "                  verticalalignment='top', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'))\n",
    "\n",
    "    if i != 0:\n",
    "        axes[5-i, 1].plot(zbin_2_wln[i], zbin_2_flux_renorm[i], color='forestgreen', alpha=alpha_values[i])\n",
    "        axes[5-i, 1].plot(zbin_2_wln[i], convolve(zbin_2_flux_renorm[i], Gaussian1DKernel(5)), color='black', alpha=1.0)\n",
    "        axes[5-i, 1].plot(zbin_2_wln[0], convolve(zbin_2_flux_renorm[0], Gaussian1DKernel(5)), color='black',linestyle = '--', alpha=0.6)\n",
    "    else:\n",
    "        axes[5-i, 1].plot(zbin_2_wln[i], zbin_2_flux_renorm[i], \n",
    "                        label = f'Raw Stacks 0.4<z<0.9 ', color='forestgreen', alpha=alpha_values[i])\n",
    "        axes[5-i, 1].plot(zbin_2_wln[i], convolve(zbin_2_flux_renorm[i], Gaussian1DKernel(5)),\n",
    "                        color='black', alpha=1.0)\n",
    "        axes[5-i, 1].plot(zbin_2_wln[0], convolve(zbin_2_flux_renorm[0], Gaussian1DKernel(5)),\n",
    "                        color='black',linestyle = '--', alpha=0.6)\n",
    "    \n",
    "\n",
    "# Plotting for zbin 3\n",
    "for i in range(2):\n",
    "    axes[5-i, 2].set_xlabel('Rest-frame wavelength, $\\lambda$ [$\\AA$]', fontsize= font)\n",
    "    axes[5-i, 2].set_ylabel('$F_{\\lambda, Norm}$ ', fontsize= font)\n",
    "    #axes[5-i, 2].legend(fontsize=12, loc='upper left')\n",
    "    axes[5-i, 2].set_xlim(1500, 5000)\n",
    "    axes[5-i, 2].set_ylim(-0.3, 4.5)\n",
    "    axes[5-i, 2].tick_params(axis='both', which='major', labelsize=font) \n",
    "    text_combined = (f'Log (M/M$\\odot$) = {zbin_3_mass_min[i]:.2f}:{zbin_3_mass_max[i]:.2f}\\n' +\n",
    "                    f'[OII] Equivalent Width [$\\AA$] = {abs(ew_int_5[i]):.2f}')\n",
    "    axes[5-i, 2].text(0.02, 0.95, text_combined, transform=axes[5-i, 2].transAxes, fontsize=10,\n",
    "                    verticalalignment='top', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'))\n",
    " \n",
    "\n",
    "    if i!= 0:\n",
    "        axes[5-i, 2].plot(zbin_3_wln[i], zbin_3_flux_renorm[i], color='indianred', alpha=alpha_values[i])\n",
    "        axes[5-i, 2].plot(zbin_3_wln[i], convolve(zbin_3_flux_renorm[i], Gaussian1DKernel(5)), color='black', alpha=1.0)\n",
    "        axes[5-i, 2].plot(zbin_3_wln[1], convolve(zbin_3_flux_renorm[1], Gaussian1DKernel(5)), color='black', linestyle = '--', alpha=0.6)\n",
    "    else:\n",
    "        axes[5-i, 2].plot(zbin_3_wln[i], zbin_3_flux_renorm[i], \n",
    "                        label = f'Raw Stacks 0.9<z<1.6 ', color='indianred', alpha=alpha_values[i])\n",
    "        axes[5-i, 2].plot(zbin_3_wln[i], convolve(zbin_3_flux_renorm[i], Gaussian1DKernel(5)),\n",
    "                        label = f'Smoothed Gaussian Stack ', color='black', alpha=1.0)\n",
    "        axes[5-i, 2].plot(zbin_3_wln[1], convolve(zbin_3_flux_renorm[1], Gaussian1DKernel(5)),\n",
    "                        label = f'Lowest Mass Bin Smoothed Gaussian Stacks', color='black', linestyle = '--', alpha=0.4)\n",
    "        \n",
    "\n",
    "# Remove x-axis label on all plots except row 5\n",
    "for i in range(6):\n",
    "    for j in range(3):\n",
    "        if i != 5:\n",
    "            axes[i, j].set_xlabel('')\n",
    "            axes[i, j].tick_params(axis='x', which='both', labelsize=0)\n",
    "\n",
    "# Remove y-axis label on all plots except column 0\n",
    "for i in range(6):\n",
    "    for j in range(3):\n",
    "        if j != 0:\n",
    "            axes[i, j].set_ylabel('')\n",
    "            axes[i, j].tick_params(axis='y', which='both', labelsize=0)\n",
    "\n",
    "# Delete rows 0, 1, 2, 3 in column 2\n",
    "for i in range(4):\n",
    "    fig.delaxes(axes[i, 2])\n",
    "\n",
    "# Delete rows 0, 1 in column 1\n",
    "for i in range(2):\n",
    "    fig.delaxes(axes[i, 1])\n",
    "\n",
    "plt.subplots_adjust(top = 0.95,hspace=.0, wspace=.0)\n",
    "\n",
    "fig.suptitle('DESI Spectra Stacks, LOFAR Class: SFG', fontsize=30)\n",
    "axes[0, 0].set_title('0.03<z<0.4', fontsize=20)\n",
    "axes[2, 1].set_title('0.4<z<0.9', fontsize=20)\n",
    "axes[4, 2].set_title('0.9<z<1.6', fontsize=20)\n",
    "fig.legend(fontsize=20, loc='upper right')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
